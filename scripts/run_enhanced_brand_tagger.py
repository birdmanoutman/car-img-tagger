#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºçš„å“ç‰Œå›¾ç‰‡æ ‡æ³¨å™¨ - æ”¯æŒå¤šæ ‡ç­¾ã€ç½®ä¿¡åº¦è¿‡æ»¤å’Œé¢œè‰²æ£€æµ‹
"""

import os
import json
import time
import warnings
from pathlib import Path

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
from tqdm import tqdm

warnings.filterwarnings('ignore')

import sys

PROJECT_ROOT = Path(__file__).resolve().parents[1]
SRC_DIR = PROJECT_ROOT / "src"
if str(SRC_DIR) not in sys.path:
    sys.path.insert(0, str(SRC_DIR))

from car_img_tagger.color_detection import CarColorDetector

class EnhancedBrandImageTagger:
    def __init__(self, model_path='models/ensemble_car_angle_classifier.pth', 
                 confidence_threshold=0.8, top_k=3, enable_color_detection=True):
        """
        åˆå§‹åŒ–å¢å¼ºçš„å“ç‰Œå›¾ç‰‡æ ‡æ³¨å™¨
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„æ ‡ç­¾å°†è¢«è¿‡æ»¤
            top_k: è¿”å›å‰kä¸ªæœ€å¯èƒ½çš„æ ‡ç­¾
            enable_color_detection: æ˜¯å¦å¯ç”¨é¢œè‰²æ£€æµ‹
        """
        self.model_path = model_path
        self.confidence_threshold = confidence_threshold
        self.top_k = top_k
        self.enable_color_detection = enable_color_detection
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.class_names = None
        self.transform = None
        self.color_detector = None
        
        # åŠ è½½æ¨¡å‹å’Œç±»åˆ«åç§°
        self.load_model()
        self.setup_transforms()
        
        # åˆå§‹åŒ–é¢œè‰²æ£€æµ‹å™¨
        if self.enable_color_detection:
            self.color_detector = CarColorDetector()
        
    def load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_path}")
        
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
        
        # åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹
        checkpoint = torch.load(self.model_path, map_location=self.device)
        
        # è·å–ç±»åˆ«åç§°
        if 'class_names' in checkpoint:
            self.class_names = checkpoint['class_names']
        else:
            # å¦‚æœæ²¡æœ‰ä¿å­˜ç±»åˆ«åç§°ï¼Œä½¿ç”¨é»˜è®¤çš„24ä¸ªç±»åˆ«
            self.class_names = [
                '1-å‰45', '2-æ­£ä¾§', '3-å45', '4-æ­£å‰', '5-æ­£å',
                '6-å¤´ç¯', '7-å°¾ç¯', '8-æ ¼æ …', '8-è½®æ¯‚', '9-å°¾ç¿¼',
                '10-å†…é¥°', '11-æ–¹å‘ç›˜', '12-ä¸­æ§å±', '13-CONSOLE', '14-åº§æ¤…',
                '15-é—¨æ¿', '16-æ—‹é’®', '16-çƒå¤´', '17-å¤©çª—', '18-åå¤‡ç®±',
                '19-å‰å¤‡ç®±', '20-å‡ºé£å£', '21-ä»ªè¡¨å±', '22-æ‰©æ•£å™¨', '23-CæŸ±', '24-å……ç”µå£'
            ]
        
        # åŠ è½½æ¨¡å‹æ¶æ„
        from ensemble_train_model import EnsembleModel
        self.model = EnsembleModel(num_classes=len(self.class_names))
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()
        
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œç±»åˆ«æ•°: {len(self.class_names)}")
        print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {self.device}")
        
    def setup_transforms(self):
        """è®¾ç½®å›¾åƒé¢„å¤„ç†å˜æ¢"""
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
    def process_image_angles(self, image_path):
        """
        å¤„ç†å›¾ç‰‡çš„è§’åº¦åˆ†ç±»
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            
        Returns:
            dict: è§’åº¦é¢„æµ‹ç»“æœ
        """
        try:
            # åŠ è½½å’Œé¢„å¤„ç†å›¾ç‰‡
            image = Image.open(image_path).convert('RGB')
            input_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            # è·å–å›¾ç‰‡ä¿¡æ¯
            width, height = image.size
            file_size = os.path.getsize(image_path)
            
            # æ¨¡å‹é¢„æµ‹
            with torch.no_grad():
                outputs = self.model(input_tensor)
                probabilities = torch.softmax(outputs, dim=1)
                
            # è·å–å‰kä¸ªé¢„æµ‹ç»“æœ
            top_probs, top_indices = torch.topk(probabilities, self.top_k, dim=1)
            
            # è¿‡æ»¤ä½ç½®ä¿¡åº¦æ ‡ç­¾
            valid_predictions = []
            for i in range(self.top_k):
                prob = top_probs[0][i].item()
                class_idx = top_indices[0][i].item()
                class_name = self.class_names[class_idx]
                
                if prob >= self.confidence_threshold:
                    valid_predictions.append({
                        'class': class_name,
                        'confidence': prob
                    })
            
            # å¦‚æœæ²¡æœ‰æ»¡è¶³é˜ˆå€¼çš„é¢„æµ‹ï¼Œè¿”å›æœ€é«˜ç½®ä¿¡åº¦çš„é¢„æµ‹
            if not valid_predictions:
                best_prob = top_probs[0][0].item()
                best_class = self.class_names[top_indices[0][0].item()]
                valid_predictions = [{
                    'class': best_class,
                    'confidence': best_prob
                }]
            
            return {
                'predictions': valid_predictions,
                'width': width,
                'height': height,
                'file_size': file_size,
                'needs_annotation': len(valid_predictions) == 0 or valid_predictions[0]['confidence'] < self.confidence_threshold
            }
            
        except Exception as e:
            print(f"âŒ è§’åº¦åˆ†ç±»å¤±è´¥ {image_path}: {str(e)}")
            return None
    
    def process_image_colors(self, image_path):
        """
        å¤„ç†å›¾ç‰‡çš„é¢œè‰²æ£€æµ‹
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            
        Returns:
            list: é¢œè‰²æ£€æµ‹ç»“æœ
        """
        if not self.enable_color_detection or self.color_detector is None:
            return []
        
        try:
            colors = self.color_detector.detect_car_color(image_path, top_k=3)
            return colors
        except Exception as e:
            print(f"âŒ é¢œè‰²æ£€æµ‹å¤±è´¥ {image_path}: {str(e)}")
            return []
    
    def process_image(self, image_path):
        """
        å¤„ç†å•å¼ å›¾ç‰‡ï¼Œè¿”å›è§’åº¦å’Œé¢œè‰²é¢„æµ‹ç»“æœ
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            
        Returns:
            dict: åŒ…å«é¢„æµ‹ç»“æœçš„å­—å…¸
        """
        # è§’åº¦åˆ†ç±»
        angle_result = self.process_image_angles(image_path)
        if angle_result is None:
            return None
        
        # é¢œè‰²æ£€æµ‹
        color_result = self.process_image_colors(image_path)
        
        # åˆå¹¶ç»“æœ
        result = angle_result.copy()
        result['colors'] = color_result
        
        return result
    
    def process_brand_folder(self, brand_path):
        """
        å¤„ç†å•ä¸ªå“ç‰Œæ–‡ä»¶å¤¹
        
        Args:
            brand_path: å“ç‰Œæ–‡ä»¶å¤¹è·¯å¾„
            
        Returns:
            list: æ ‡æ³¨ç»“æœåˆ—è¡¨
        """
        brand_name = os.path.basename(brand_path)
        results = []
        
        print(f"ğŸ”„ æ­£åœ¨å¤„ç†å“ç‰Œ: {brand_name}")
        
        # éå†è½¦å‹æ–‡ä»¶å¤¹
        car_models = [d for d in os.listdir(brand_path) 
                     if os.path.isdir(os.path.join(brand_path, d))]
        
        for car_model in tqdm(car_models, desc=f"å¤„ç† {brand_name}"):
            car_model_path = os.path.join(brand_path, car_model)
            
            # è·å–å›¾ç‰‡æ–‡ä»¶
            image_files = []
            for ext in ['*.jpg', '*.jpeg', '*.png', '*.webp']:
                image_files.extend(Path(car_model_path).glob(ext))
            
            for image_file in image_files:
                image_path = str(image_file)
                image_id = f"brand_{os.path.basename(image_path).split('.')[0]}"
                
                # å¤„ç†å›¾ç‰‡
                result = self.process_image(image_path)
                if result is None:
                    continue
                
                # æ„å»ºç»“æœè®°å½•
                record = {
                    'image_path': image_path,
                    'image_id': image_id,
                    'brand': brand_name,
                    'car_model': car_model,
                    'width': result['width'],
                    'height': result['height'],
                    'file_size': result['file_size'],
                    'source': 'brand_images',
                    'needs_annotation': result['needs_annotation'],
                    'auto_tags': [pred['class'] for pred in result['predictions']],
                    'manual_tags': [],
                    'confidence_scores': [pred['confidence'] for pred in result['predictions']],
                    'primary_angle': result['predictions'][0]['class'] if result['predictions'] else 'unknown',
                    'primary_confidence': result['predictions'][0]['confidence'] if result['predictions'] else 0.0,
                    'total_predictions': len(result['predictions']),
                    'colors': [color['color'] for color in result['colors']],
                    'color_confidences': [color['confidence'] for color in result['colors']],
                    'primary_color': result['colors'][0]['color'] if result['colors'] else 'unknown',
                    'primary_color_confidence': result['colors'][0]['confidence'] if result['colors'] else 0.0,
                    'color_details': result['colors']
                }
                
                results.append(record)
        
        return results
    
    def process_all_brands(self, brands_dir='å›¾ç‰‡ç´ æ', output_file='processed_data/enhanced_brand_images_annotated.csv'):
        """
        å¤„ç†æ‰€æœ‰å“ç‰Œæ–‡ä»¶å¤¹
        
        Args:
            brands_dir: å“ç‰Œæ–‡ä»¶å¤¹ç›®å½•
            output_file: è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸš€ å¼€å§‹å¤„ç†æ‰€æœ‰å“ç‰Œå›¾ç‰‡...")
        print(f"ğŸ“ å“ç‰Œç›®å½•: {brands_dir}")
        print(f"ğŸ¯ ç½®ä¿¡åº¦é˜ˆå€¼: {self.confidence_threshold}")
        print(f"ğŸ”¢ è¿”å›å‰{self.top_k}ä¸ªé¢„æµ‹")
        print(f"ğŸ¨ é¢œè‰²æ£€æµ‹: {'å¯ç”¨' if self.enable_color_detection else 'ç¦ç”¨'}")
        
        all_results = []
        
        # è·å–æ‰€æœ‰å“ç‰Œæ–‡ä»¶å¤¹
        brand_folders = [d for d in os.listdir(brands_dir) 
                        if os.path.isdir(os.path.join(brands_dir, d))]
        
        for brand_folder in brand_folders:
            brand_path = os.path.join(brands_dir, brand_folder)
            brand_results = self.process_brand_folder(brand_path)
            all_results.extend(brand_results)
        
        # ä¿å­˜ç»“æœåˆ°CSV
        if all_results:
            df = pd.DataFrame(all_results)
            df.to_csv(output_file, index=False, encoding='utf-8')
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_images = len(df)
            high_confidence = len(df[df['primary_confidence'] >= self.confidence_threshold])
            multi_label = len(df[df['total_predictions'] > 1])
            needs_annotation = len(df[df['needs_annotation'] == True])
            has_colors = len(df[df['primary_color'] != 'unknown'])
            
            print(f"\nğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡:")
            print(f"   ğŸ“¸ æ€»å›¾ç‰‡æ•°: {total_images}")
            print(f"   âœ… é«˜ç½®ä¿¡åº¦å›¾ç‰‡: {high_confidence} ({high_confidence/total_images*100:.1f}%)")
            print(f"   ğŸ·ï¸  å¤šæ ‡ç­¾å›¾ç‰‡: {multi_label} ({multi_label/total_images*100:.1f}%)")
            print(f"   âš ï¸  éœ€è¦äººå·¥æ ‡æ³¨: {needs_annotation} ({needs_annotation/total_images*100:.1f}%)")
            if self.enable_color_detection:
                print(f"   ğŸ¨ æ£€æµ‹åˆ°é¢œè‰²: {has_colors} ({has_colors/total_images*100:.1f}%)")
            print(f"   ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            
            return df
        else:
            print("âŒ æ²¡æœ‰å¤„ç†ä»»ä½•å›¾ç‰‡")
            return None

def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºå¢å¼ºçš„æ ‡æ³¨å™¨
    tagger = EnhancedBrandImageTagger(
        model_path='models/ensemble_car_angle_classifier.pth',
        confidence_threshold=0.8,  # 80%ç½®ä¿¡åº¦é˜ˆå€¼
        top_k=3,  # è¿”å›å‰3ä¸ªé¢„æµ‹
        enable_color_detection=True  # å¯ç”¨é¢œè‰²æ£€æµ‹
    )
    
    # å¤„ç†æ‰€æœ‰å“ç‰Œ
    results_df = tagger.process_all_brands()
    
    if results_df is not None:
        print("\nğŸ‰ å¢å¼ºçš„å“ç‰Œå›¾ç‰‡æ ‡æ³¨å®Œæˆï¼")
        print("ğŸ’¡ ç°åœ¨æ¯å¼ å›¾ç‰‡åŒ…å«:")
        print("   - å¤šä¸ªè§’åº¦æ ‡ç­¾ï¼ˆç½®ä¿¡åº¦è¿‡æ»¤ï¼‰")
        print("   - è½¦èº«é¢œè‰²æ£€æµ‹")
        print("   - è¯¦ç»†çš„ç½®ä¿¡åº¦ä¿¡æ¯")

if __name__ == "__main__":
    main()
